{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50df4a78",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Project\n",
    "\n",
    "This notebook demonstrates a complete workflow for binary sentiment classification on movie reviews. It includes data exploration, text preprocessing, feature engineering, model training, and evaluation steps.\n",
    "\n",
    "### Steps:\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Text Preprocessing\n",
    "- Model Training and Evaluation\n",
    "- Business Insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ed29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0e6f6",
   "metadata": {},
   "source": [
    "## Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf74f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41022306",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 1. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddbd5df",
   "metadata": {},
   "source": [
    "### 2. Text Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['review'].apply(len)\n",
    "sns.histplot(df['text_length'], bins=50)\n",
    "plt.title('Text Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97aadfb",
   "metadata": {},
   "source": [
    "### 3. Common Words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(df['review']).split()\n",
    "word_freq = Counter(all_words)\n",
    "common_words = word_freq.most_common(20)\n",
    "\n",
    "common_words_df = pd.DataFrame(common_words, columns=['Word', 'Frequency'])\n",
    "sns.barplot(x='Frequency', y='Word', data=common_words_df)\n",
    "plt.title('Top 20 Most Common Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb70e3",
   "metadata": {},
   "source": [
    "### 4. Word Clouds for Positive and Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = ' '.join(df[df['sentiment'] == 'positive']['review'].tolist())\n",
    "negative_reviews = ' '.join(df[df['sentiment'] == 'negative']['review'].tolist())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Positive Reviews WordCloud')\n",
    "plt.imshow(WordCloud(width=300, height=200, background_color='white').generate(positive_reviews), interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Negative Reviews WordCloud')\n",
    "plt.imshow(WordCloud(width=300, height=200, background_color='white').generate(negative_reviews), interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c966ad",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['review'].apply(preprocess_text)\n",
    "df[['review', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d6ede",
   "metadata": {},
   "source": [
    "### Feature Engineering: Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea99b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('data/glove.6B.50d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print('Loaded word vectors:', len(embeddings_index))\n",
    "\n",
    "def get_average_embedding(tokens):\n",
    "    valid_embeddings = [embeddings_index[word] for word in tokens if word in embeddings_index]\n",
    "    if not valid_embeddings:\n",
    "        return np.zeros(50)\n",
    "    return np.mean(valid_embeddings, axis=0)\n",
    "\n",
    "df['embedding'] = df['tokens'].apply(get_average_embedding)\n",
    "\n",
    "train_x = np.vstack(df['embedding'].values)\n",
    "train_y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e41f9b",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "model_performance = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    predictions = model.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    precision = precision_score(test_y, predictions)\n",
    "    recall = recall_score(test_y, predictions)\n",
    "    f1 = f1_score(test_y, predictions)\n",
    "\n",
    "    model_performance[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45bc7a",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384265c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(model_performance, key=lambda name: model_performance[name]['accuracy'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_model, 'outputs/best_model.pkl')\n",
    "\n",
    "print(f'Saved the best model ({best_model_name}) with accuracy: {model_performance[best_model_name]['accuracy']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266f54c",
   "metadata": {},
   "source": [
    "## Conclusion and Business Insights\n",
    "\n",
    "- The best-performing model for binary sentiment classification was saved for deployment.\n",
    "- This model can be valuable in applications like review aggregation, customer feedback analysis, and understanding user sentiment in real-time.\n",
    "- By automating sentiment classification, businesses can better gauge public opinion and respond to trends more effectively."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
